{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from os import getcwd\n",
    "from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/Senthils Legion/Desktop/Data Science Course Materials/Face_mask/Face Mask Dataset'\n",
    "\n",
    "train_dir = os.path.join(base_dir,'Train')\n",
    "test_dir = os.path.join(base_dir,'Test')\n",
    "valid_dir = os.path.join(base_dir,'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 992 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255.0,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.0,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255.0,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size = 10,\n",
    "                                                    class_mode='binary',\n",
    "                                                    classes = ['WithMask','WithoutMask'])\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(150,150),\n",
    "                                                  batch_size = 10,\n",
    "                                                  class_mode='binary',\n",
    "                                                  classes = ['WithMask','WithoutMask'])\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size = 10,\n",
    "                                                    class_mode='binary',\n",
    "                                                    classes = ['WithMask','WithoutMask'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MYmodel():\n",
    "    inputs = tf.keras.Input(shape = (150,150,3))\n",
    "    x = tf.keras.layers.Conv2D(32,3,activation = 'relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64,3,activation = 'relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(128,3,activation = 'relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "    flatten_layer = tf.keras.layers.Flatten()\n",
    "    x = flatten_layer(x)\n",
    "    x = tf.keras.layers.Dense(512,activation = 'relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1,activation = 'sigmoid')(x)\n",
    "\n",
    "    model_1 = tf.keras.Model(inputs,outputs ,name = 'model_1')\n",
    "\n",
    "    return model_1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "100/100 [==============================] - 83s 789ms/step - loss: 2.2263 - accuracy: 0.8200 - val_loss: 2.5837 - val_accuracy: 0.5100\n",
      "Epoch 2/7\n",
      "100/100 [==============================] - 71s 714ms/step - loss: 0.6789 - accuracy: 0.8800 - val_loss: 3.4762 - val_accuracy: 0.5180\n",
      "Epoch 3/7\n",
      "100/100 [==============================] - 59s 585ms/step - loss: 0.6621 - accuracy: 0.8480 - val_loss: 0.4392 - val_accuracy: 0.8540\n",
      "Epoch 4/7\n",
      "100/100 [==============================] - 52s 520ms/step - loss: 0.3110 - accuracy: 0.8990 - val_loss: 0.2832 - val_accuracy: 0.8880\n",
      "Epoch 5/7\n",
      "100/100 [==============================] - 60s 594ms/step - loss: 0.2814 - accuracy: 0.9040 - val_loss: 0.1907 - val_accuracy: 0.9180\n",
      "Epoch 6/7\n",
      "100/100 [==============================] - 52s 513ms/step - loss: 0.2137 - accuracy: 0.9190 - val_loss: 0.2506 - val_accuracy: 0.9120\n",
      "Epoch 7/7\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.2735 - accuracy: 0.9100 - val_loss: 0.3095 - val_accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "model = MYmodel()\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.001),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, validation_data = valid_generator, epochs = 7,steps_per_epoch = 100 ,validation_steps = 50)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8585205 , 0.96410656, 0.8569007 , 0.98296154, 0.9589586 ,\n",
       "       0.9696168 , 0.97487605, 0.6886051 , 0.972009  , 0.93798923,\n",
       "       0.9685916 , 0.96026266, 0.525875  , 0.7915728 , 0.86852795,\n",
       "       0.99298465, 0.9318199 , 0.9825951 , 0.92766577, 0.7453521 ,\n",
       "       0.9941963 , 0.71775377, 0.9805879 , 0.9759052 , 0.94718564,\n",
       "       0.94948536, 0.8840332 , 0.94692564, 0.83802116, 0.97968936,\n",
       "       0.99179786, 0.9875355 , 0.9602077 , 0.659659  , 0.89936244,\n",
       "       0.6098745 , 0.81385493, 0.96173537, 0.9668283 , 0.74973476,\n",
       "       0.7135805 , 0.9718255 , 0.9490138 , 0.6319757 , 0.5427829 ,\n",
       "       0.9755962 , 0.81740034, 0.9348052 , 0.8711283 , 0.9733312 ,\n",
       "       0.8079957 , 0.6047275 , 0.89046955, 0.9866396 , 0.7420473 ,\n",
       "       0.950664  , 0.97086483, 0.9216547 , 0.6672009 , 0.73523307,\n",
       "       0.8981818 , 0.924303  , 0.957378  , 0.723119  , 0.97181165,\n",
       "       0.96760166, 0.9013939 , 0.9546524 , 0.96413434, 0.6316978 ,\n",
       "       0.94760984, 0.83196956, 0.57583344, 0.8987417 , 0.72402805,\n",
       "       0.8237798 , 0.9786656 , 0.551136  , 0.94656956, 0.9883125 ,\n",
       "       0.9918025 , 0.9340445 , 0.5428143 , 0.91717947, 0.94645464,\n",
       "       0.53368056, 0.95981747, 0.8274256 , 0.9054632 , 0.98530126,\n",
       "       0.8809008 , 0.5732241 , 0.97647035, 0.51301605, 0.974385  ,\n",
       "       0.9604869 , 0.9489238 , 0.98601407, 0.967348  , 0.9021847 ,\n",
       "       0.7007567 , 0.97789586, 0.9692012 , 0.9157299 , 0.61748004,\n",
       "       0.94200563, 0.9643544 , 0.90217173, 0.80104136, 0.71371233,\n",
       "       0.98097074, 0.9620726 , 0.8988583 , 0.89878416, 0.81313396,\n",
       "       0.6694796 , 0.9735172 , 0.9779364 , 0.7951182 , 0.8813845 ,\n",
       "       0.81514686, 0.9862021 , 0.9454423 , 0.767797  , 0.95619416,\n",
       "       0.6526191 , 0.90184796, 0.96142757, 0.97202194, 0.990394  ,\n",
       "       0.9386195 , 0.8974813 , 0.97447455, 0.9097098 , 0.7352118 ,\n",
       "       0.7128119 , 0.9289934 , 0.9454409 , 0.96762836, 0.97041345,\n",
       "       0.88185674, 0.88056064, 0.9447456 , 0.8453826 , 0.938074  ,\n",
       "       0.9860921 , 0.98730075, 0.9791914 , 0.9358922 , 0.9411516 ,\n",
       "       0.9702674 , 0.9831948 , 0.943761  , 0.6805468 , 0.8802898 ,\n",
       "       0.9875494 , 0.98581207, 0.62243056, 0.9938866 , 0.8602252 ,\n",
       "       0.7402859 , 0.6554806 , 0.9852612 , 0.7210364 , 0.5339642 ,\n",
       "       0.95634604, 0.9391171 , 0.79918534, 0.7250926 , 0.6256904 ,\n",
       "       0.6646337 , 0.97755516, 0.82638204, 0.95786095, 0.87788403,\n",
       "       0.78636837, 0.95740443, 0.98442423, 0.9228744 , 0.5112792 ,\n",
       "       0.97704184, 0.9765317 , 0.9718052 , 0.97783065, 0.8458185 ,\n",
       "       0.6985369 , 0.96551824, 0.87510866, 0.8427141 , 0.9484696 ,\n",
       "       0.9735987 , 0.9738921 , 0.84441805, 0.90451694, 0.80947614,\n",
       "       0.9794711 , 0.90592724, 0.9442135 , 0.9442769 , 0.50440174,\n",
       "       0.958251  , 0.9667566 , 0.9693154 , 0.95696473, 0.79148924,\n",
       "       0.8313134 , 0.70620966, 0.9073786 , 0.9224732 , 0.9095873 ,\n",
       "       0.6878876 , 0.8811953 , 0.9955729 , 0.97245014, 0.90527964,\n",
       "       0.878203  , 0.62316376, 0.78377986, 0.7931099 , 0.9465474 ,\n",
       "       0.9931469 , 0.9540434 , 0.8206874 , 0.969262  , 0.82581735,\n",
       "       0.89064753, 0.80860573, 0.9712074 , 0.9871316 , 0.98458505,\n",
       "       0.97705793, 0.9843788 , 0.84930754, 0.81084776, 0.7605167 ,\n",
       "       0.9569504 , 0.9449763 , 0.9886689 , 0.8447524 , 0.9506458 ,\n",
       "       0.99481654, 0.7297888 , 0.7690023 , 0.9359213 , 0.98414797,\n",
       "       0.9699094 , 0.73513615, 0.73438966, 0.97687685, 0.9733591 ,\n",
       "       0.9848557 , 0.9095051 , 0.83409643, 0.93293786, 0.97274595,\n",
       "       0.71325403, 0.97910064, 0.908051  , 0.9117837 , 0.89863783,\n",
       "       0.72692525, 0.9144331 , 0.977969  , 0.90965027, 0.9660106 ,\n",
       "       0.77600175, 0.97884846, 0.6964893 , 0.61576146, 0.94648707,\n",
       "       0.94573075, 0.9996313 , 0.74305737, 0.6210358 , 0.9628473 ,\n",
       "       0.9366531 , 0.8079934 , 0.88933676, 0.8903073 , 0.97473925,\n",
       "       0.7635745 , 0.943414  , 0.99488664, 0.92344403, 0.65561056,\n",
       "       0.97713745, 0.6970702 , 0.90204537, 0.95604795, 0.5777261 ,\n",
       "       0.930872  , 0.9318646 , 0.85114753, 0.97796303, 0.9682959 ,\n",
       "       0.8396089 , 0.9810253 , 0.6697633 , 0.74683744, 0.97737384,\n",
       "       0.5864558 , 0.9037482 , 0.5247002 , 0.92020375, 0.710486  ,\n",
       "       0.7828287 , 0.5981022 , 0.8822502 , 0.96544206, 0.6345026 ,\n",
       "       0.98475206, 0.6411139 , 0.52722085, 0.852782  , 0.6386865 ,\n",
       "       0.86691785, 0.942024  , 0.5808387 , 0.9019841 , 0.76039124,\n",
       "       0.9133506 , 0.75491947, 0.7194827 , 0.67754483, 0.95157015,\n",
       "       0.9534223 , 0.95341605, 0.9621179 , 0.9817147 , 0.9914192 ,\n",
       "       0.9700669 , 0.95462763, 0.91601765, 0.9335377 , 0.99547064,\n",
       "       0.9146397 , 0.9966884 , 0.5707348 , 0.9875506 , 0.971766  ,\n",
       "       0.50532115, 0.89442307, 0.9294786 , 0.9920119 , 0.64797574,\n",
       "       0.9775567 , 0.88928884, 0.8677952 , 0.9385829 , 0.9092753 ,\n",
       "       0.91592336, 0.72442174, 0.93681127, 0.65763587, 0.92059064,\n",
       "       0.7928543 , 0.9206674 , 0.6610955 , 0.7968968 , 0.99626744,\n",
       "       0.95640767, 0.9527347 , 0.7054197 , 0.95994866, 0.88404596,\n",
       "       0.8227439 , 0.93915534, 0.99026346, 0.9579419 , 0.68532705,\n",
       "       0.6710989 , 0.72449094, 0.9495548 , 0.7404727 , 0.7922547 ,\n",
       "       0.98402506, 0.81289566, 0.70124763, 0.93658483, 0.9331478 ,\n",
       "       0.9694848 , 0.95036185, 0.98303735, 0.8791478 , 0.6962697 ,\n",
       "       0.9171262 , 0.9879968 , 0.9270113 , 0.9683868 , 0.95085555,\n",
       "       0.990372  , 0.5199429 , 0.53914   , 0.75730515, 0.9877981 ,\n",
       "       0.9703527 , 0.97960365, 0.8425275 , 0.9876416 , 0.66455865,\n",
       "       0.5832255 , 0.82158923, 0.96084327, 0.710877  , 0.60826313,\n",
       "       0.97818476, 0.99147207, 0.84220487, 0.98291385, 0.98477185,\n",
       "       0.7810991 , 0.9395972 , 0.5332135 , 0.9421847 , 0.70338035,\n",
       "       0.83136356, 0.64113075, 0.62016636, 0.9719601 , 0.9797684 ,\n",
       "       0.6863051 , 0.76537687, 0.9490497 ], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try to import Resnet model and use it for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets build the predictor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictor(captures):\n",
    "\n",
    "  ## uploaded = cv2.imread('mask1.jpg')\n",
    "\n",
    "  #img = image.load_img('nomask.jfif', target_size = (150,150))\n",
    "\n",
    "  img = cv2.cvtColor(captures,cv2.COLOR_BGR2GRAY)\n",
    "  img = cv2.resize(captures,(150,150))\n",
    "\n",
    "  ## plt.imshow(img)\n",
    "  x = image.img_to_array(img)/255.0\n",
    "  x = np.expand_dims(x,axis = 0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  ## print(images.shape)\n",
    "  predict_proba = model.predict(images,batch_size =10)\n",
    "\n",
    "\n",
    "  if predict_proba[0]>0.5:\n",
    "    predict_class = 0\n",
    "    ##print('No Mask Detected')\n",
    "    return predict_proba,predict_class\n",
    "  else:\n",
    "    predict_class = 1\n",
    "    ## print('Mask Detected')\n",
    "    return (1-predict_proba)*100 , predict_class \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = image.load_img('nomask.jfif', target_size = (150,150))\n",
    "l = image.img_to_array(z)\n",
    "a, b = predictor(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.895051]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets make a face detector which will detect face and provide the face as the input for our model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from mtcnn) (2.7.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\anaconda3\\lib\\site-packages (from mtcnn) (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\anaconda3\\lib\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.20.1)\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip instal mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recog():\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    classes = ['WithoutMask','WithMask']\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(gray,1.1,5,minSize = (150,150),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        faces_list = []\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "\n",
    "\n",
    "            img = np.copy(frame[y:y+h,x:x+w])\n",
    "\n",
    "            probability,class_label = predictor(img)\n",
    "            if class_label == 1:\n",
    "                drawn_rectangle = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                cv2.putText(drawn_rectangle,str(probability),(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "            else:\n",
    "                drawn_rectangle = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "                cv2.putText(drawn_rectangle,str(probability),(x,y-10),cv2.FONT_HERSHEY_COMPLEX,0.9,(0,0,255),2)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef9e06bb236b2a8629b07e87a04b187b952a0f661eff5533360a155783f0c33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
